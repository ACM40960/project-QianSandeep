{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch daily S&P 500 data\n",
    "sp500_data = yf.download('^GSPC', start='2000-01-01', end='2024-01-01')\n",
    "\n",
    "# Calculate additional features for S&P 500 data\n",
    "sp500_data['daily_return'] = sp500_data['Close'].pct_change() #might need\n",
    "sp500_data['volatility'] = sp500_data['daily_return'].rolling(window=20).std()\n",
    "\n",
    "###sp500_data['ma_200'] = sp500_data['Close'].rolling(window=200).mean() # for long term\n",
    "\n",
    "\n",
    "# Calculate the 200-day moving return\n",
    "sp500_data['200_day_return'] = sp500_data['Close'].pct_change(periods=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5837, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500 = sp500_data.dropna()\n",
    "sp500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as pdr\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch economic indicators from FRED\n",
    "gdp = pdr.get_data_fred('GDP', start='2000-01-01', end='2024-01-01') #quaterly\n",
    "\n",
    "inflation = pdr.get_data_fred('CPIAUCSL', start='2000-01-01', end='2024-01-01')  # CPI for inflation\n",
    "unemployment = pdr.get_data_fred('UNRATE', start='2000-01-01', end='2024-01-01')\n",
    "interest_rate = pdr.get_data_fred('FEDFUNDS', start='2000-01-01', end='2024-01-01')\n",
    "\n",
    "# Rename columns for clarity\n",
    "gdp.rename(columns={'GDP': 'GDP'}, inplace=True)\n",
    "inflation.rename(columns={'CPIAUCSL': 'Inflation'}, inplace=True)\n",
    "unemployment.rename(columns={'UNRATE': 'Unemployment'}, inplace=True)\n",
    "interest_rate.rename(columns={'FEDFUNDS': 'Interest_Rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-28</th>\n",
       "      <td>21706.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-29</th>\n",
       "      <td>21706.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>21706.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>21706.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>19913.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GDP\n",
       "DATE                 \n",
       "2020-03-28  21706.513\n",
       "2020-03-29  21706.513\n",
       "2020-03-30  21706.513\n",
       "2020-03-31  21706.513\n",
       "2020-04-01  19913.143"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP = gdp.resample('D').ffill()\n",
    "GDP.loc['2020-03-28':'2020-04-01'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inflation = inflation.resample('D').ffill()\n",
    "Unemployment = unemployment.resample('D').ffill()\n",
    "Interest_rate = interest_rate.resample('D').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>volatility</th>\n",
       "      <th>200_day_return</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Interest_Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-10-17</th>\n",
       "      <td>1374.619995</td>\n",
       "      <td>1380.989990</td>\n",
       "      <td>1342.339966</td>\n",
       "      <td>1349.969971</td>\n",
       "      <td>1349.969971</td>\n",
       "      <td>1.161500e+09</td>\n",
       "      <td>-0.017932</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>-0.072326</td>\n",
       "      <td>173.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-18</th>\n",
       "      <td>1349.969971</td>\n",
       "      <td>1356.650024</td>\n",
       "      <td>1305.790039</td>\n",
       "      <td>1342.130005</td>\n",
       "      <td>1342.130005</td>\n",
       "      <td>1.441700e+09</td>\n",
       "      <td>-0.005808</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>-0.040938</td>\n",
       "      <td>173.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-19</th>\n",
       "      <td>1342.130005</td>\n",
       "      <td>1389.930054</td>\n",
       "      <td>1342.130005</td>\n",
       "      <td>1388.760010</td>\n",
       "      <td>1388.760010</td>\n",
       "      <td>1.297900e+09</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>0.016088</td>\n",
       "      <td>-0.009521</td>\n",
       "      <td>173.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-20</th>\n",
       "      <td>1388.760010</td>\n",
       "      <td>1408.469971</td>\n",
       "      <td>1382.189941</td>\n",
       "      <td>1396.930054</td>\n",
       "      <td>1396.930054</td>\n",
       "      <td>1.177400e+09</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>-0.004646</td>\n",
       "      <td>173.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-23</th>\n",
       "      <td>1396.930054</td>\n",
       "      <td>1406.959961</td>\n",
       "      <td>1387.750000</td>\n",
       "      <td>1395.780029</td>\n",
       "      <td>1395.780029</td>\n",
       "      <td>1.046800e+09</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>0.016139</td>\n",
       "      <td>-0.031697</td>\n",
       "      <td>173.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2000-10-17  1374.619995  1380.989990  1342.339966  1349.969971  1349.969971   \n",
       "2000-10-18  1349.969971  1356.650024  1305.790039  1342.130005  1342.130005   \n",
       "2000-10-19  1342.130005  1389.930054  1342.130005  1388.760010  1388.760010   \n",
       "2000-10-20  1388.760010  1408.469971  1382.189941  1396.930054  1396.930054   \n",
       "2000-10-23  1396.930054  1406.959961  1387.750000  1395.780029  1395.780029   \n",
       "\n",
       "                  Volume  daily_return  volatility  200_day_return  Inflation  \\\n",
       "Date                                                                            \n",
       "2000-10-17  1.161500e+09     -0.017932    0.013576       -0.072326      173.9   \n",
       "2000-10-18  1.441700e+09     -0.005808    0.013576       -0.040938      173.9   \n",
       "2000-10-19  1.297900e+09      0.034743    0.016088       -0.009521      173.9   \n",
       "2000-10-20  1.177400e+09      0.005883    0.016181       -0.004646      173.9   \n",
       "2000-10-23  1.046800e+09     -0.000823    0.016139       -0.031697      173.9   \n",
       "\n",
       "            Unemployment  Interest_Rate  \n",
       "Date                                     \n",
       "2000-10-17           3.9           6.51  \n",
       "2000-10-18           3.9           6.51  \n",
       "2000-10-19           3.9           6.51  \n",
       "2000-10-20           3.9           6.51  \n",
       "2000-10-23           3.9           6.51  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = sp500.join([Inflation, Unemployment, Interest_rate], how='left')\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1\n",
    "\n",
    "We use top 5 companies in US.\n",
    "\n",
    "\n",
    "Apple, Microsoft, Amazon, Google, NVIDIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2\n",
    "\n",
    "If we include some independent company as our feature, we avoid adding bias but also we are adding a feature that demonstrates the market state.\n",
    "\n",
    "KKR,\n",
    "Dell Technologies,\t\n",
    "Veeva Systems\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5836,) (5836, 9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.48      0.44      0.46       545\n",
      "           1       0.54      0.58      0.56       623\n",
      "\n",
      "    accuracy                           0.51      1168\n",
      "   macro avg       0.51      0.51      0.51      1168\n",
      "weighted avg       0.51      0.51      0.51      1168\n",
      "\n",
      "Out-of-Sample Accuracy: 0.5128424657534246\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# y\n",
    "y = np.where(merged_data['Close'].shift(-1) > merged_data['Close'], 1, -1)\n",
    "# feature\n",
    "X = merged_data.drop(columns=['Close', 'daily_return', '200_day_return']).shift(1)\n",
    "\n",
    "\n",
    "y = y[:-1]\n",
    "X = X.dropna()\n",
    "\n",
    "\n",
    "y = y[-len(X):]\n",
    "\n",
    "# Check the shape of 'y' and 'X'\n",
    "print(y.shape, X.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "# Calculate the accuracy score\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Out-of-Sample Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.08      0.14       545\n",
      "           1       0.53      0.91      0.67       623\n",
      "\n",
      "    accuracy                           0.52      1168\n",
      "   macro avg       0.49      0.50      0.40      1168\n",
      "weighted avg       0.49      0.52      0.42      1168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# Create an instance of SVM\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=1, gamma=0.1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.9920715019259311\n",
      "R2 Score: 0.0034843590179204353\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2 Score: {r2}')\n",
    "# accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sande\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9967\n",
      "Epoch 2/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9924\n",
      "Epoch 3/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9916\n",
      "Epoch 4/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9912\n",
      "Epoch 5/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9909\n",
      "Epoch 6/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9907\n",
      "Epoch 7/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9905\n",
      "Epoch 8/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9905\n",
      "Epoch 9/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9904\n",
      "Epoch 10/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9903\n",
      "Epoch 11/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9903\n",
      "Epoch 12/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9902\n",
      "Epoch 13/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9902\n",
      "Epoch 14/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9902\n",
      "Epoch 15/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9902\n",
      "Epoch 16/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9901\n",
      "Epoch 17/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9901\n",
      "Epoch 18/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9901\n",
      "Epoch 19/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9900\n",
      "Epoch 20/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9900\n",
      "Epoch 21/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9900\n",
      "Epoch 22/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9899\n",
      "Epoch 23/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9899\n",
      "Epoch 24/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9899\n",
      "Epoch 25/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9898\n",
      "Epoch 26/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9898\n",
      "Epoch 27/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9897\n",
      "Epoch 28/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9897\n",
      "Epoch 29/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9897\n",
      "Epoch 30/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9896\n",
      "Epoch 31/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9896\n",
      "Epoch 32/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9895\n",
      "Epoch 33/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9895\n",
      "Epoch 34/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9894\n",
      "Epoch 35/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9894\n",
      "Epoch 36/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9893\n",
      "Epoch 37/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9893\n",
      "Epoch 38/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9892\n",
      "Epoch 39/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9892\n",
      "Epoch 40/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9891\n",
      "Epoch 41/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9891\n",
      "Epoch 42/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9890\n",
      "Epoch 43/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9890\n",
      "Epoch 44/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9889\n",
      "Epoch 45/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9888\n",
      "Epoch 46/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9888\n",
      "Epoch 47/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9887\n",
      "Epoch 48/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9887\n",
      "Epoch 49/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9886\n",
      "Epoch 50/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9886\n",
      "Epoch 51/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9885\n",
      "Epoch 52/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9884\n",
      "Epoch 53/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9884\n",
      "Epoch 54/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9883\n",
      "Epoch 55/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9883\n",
      "Epoch 56/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9882\n",
      "Epoch 57/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9881\n",
      "Epoch 58/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9881\n",
      "Epoch 59/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9880\n",
      "Epoch 60/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9879\n",
      "Epoch 61/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9879\n",
      "Epoch 62/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9878\n",
      "Epoch 63/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9877\n",
      "Epoch 64/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9877\n",
      "Epoch 65/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9876\n",
      "Epoch 66/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9876\n",
      "Epoch 67/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9875\n",
      "Epoch 68/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9874\n",
      "Epoch 69/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9874\n",
      "Epoch 70/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9873\n",
      "Epoch 71/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9873\n",
      "Epoch 72/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9872\n",
      "Epoch 73/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9871\n",
      "Epoch 74/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9871\n",
      "Epoch 75/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9870\n",
      "Epoch 76/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9870\n",
      "Epoch 77/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9869\n",
      "Epoch 78/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9868\n",
      "Epoch 79/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9868\n",
      "Epoch 80/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9867\n",
      "Epoch 81/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9867\n",
      "Epoch 82/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9866\n",
      "Epoch 83/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9866\n",
      "Epoch 84/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9865\n",
      "Epoch 85/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9865\n",
      "Epoch 86/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9864\n",
      "Epoch 87/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9864\n",
      "Epoch 88/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9863\n",
      "Epoch 89/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9863\n",
      "Epoch 90/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9863\n",
      "Epoch 91/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9862\n",
      "Epoch 92/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9862\n",
      "Epoch 93/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9861\n",
      "Epoch 94/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9861\n",
      "Epoch 95/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9861\n",
      "Epoch 96/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9860\n",
      "Epoch 97/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9860\n",
      "Epoch 98/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9860\n",
      "Epoch 99/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9859\n",
      "Epoch 100/100\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9859\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Mean Squared Error: 1.0015010666310973\n",
      "R2 Score: -0.005987446893355841\n"
     ]
    }
   ],
   "source": [
    "# lstm with keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an LSTM layer\n",
    "model.add(LSTM(100, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=10, shuffle=False)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# accuracy\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2 Score: {r2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- We create for sp500\n",
    "Then we use same features for  -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
